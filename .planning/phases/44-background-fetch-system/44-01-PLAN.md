---
phase: 44-background-fetch-system
plan: 01
type: execute
---

<objective>
Create a centralized fetch coordinator to manage background data fetching with deduplication, priority queuing, and monitoring.

Purpose: Prevent duplicate requests when multiple widgets need the same data, coordinate fetch priorities, and provide visibility into cache performance.
Output: FetchCoordinator service that widgets use for all data fetching, with automatic deduplication and priority handling.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/43-widget-cache-hydration/43-01-SUMMARY.md
@src/utils/widget-cache.ts
@src/components/a2ui/ClaudeUsageCard.tsx
@src/services/mcp-client.ts

**Current State:**
- Phase 43: Cache hydration working in ClaudeUsageCard
- Background fetch happens after cache display
- No deduplication - multiple widgets can request same data simultaneously
- No priority system - all requests treated equally
- Limited monitoring - only basic cache age tracking

**Problem:**
When multiple widgets need the same data (e.g., 3 AWS cost widgets all fetching monthly costs):
1. All 3 trigger separate fetch requests
2. Wastes bandwidth and server resources
3. No coordination of priorities
4. No visibility into cache hit rates

**Tech stack available:**
- TypeScript for type safety
- React hooks for widget integration
- localStorage-based cache (Phase 42)
- MCP client for data fetching

**Established patterns:**
- Widgets check cache synchronously, then fetch in background
- Cache operations are silent (never break widgets)
- Staleness threshold determines when to show indicators

**Constraining decisions:**
- Phase 43: Widgets initialize with cached data before first render
- Phase 42: Cache keys are `{widgetType}:{cacheKey}`
- Existing fetch functions in mcpClient should be wrapped, not replaced
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create FetchCoordinator service</name>
  <files>src/services/fetch-coordinator.ts</files>
  <action>
Create new fetch-coordinator.ts service to manage background fetches with deduplication.

**Core Interface:**
```typescript
interface FetchRequest<T> {
  key: string;              // Unique request identifier
  fetcher: () => Promise<T>; // Function that performs the fetch
  priority?: number;         // Higher = more urgent (default: 0)
  onSuccess?: (data: T) => void;
  onError?: (error: Error) => void;
}

interface FetchCoordinator {
  fetch<T>(request: FetchRequest<T>): Promise<T>;
  cancelAll(): void;
  getStats(): FetchStats;
}

interface FetchStats {
  inFlight: number;           // Currently executing requests
  queued: number;             // Waiting in queue
  completed: number;          // Total completed
  deduplicated: number;       // Requests that were deduplicated
  errors: number;             // Failed requests
}
```

**Implementation Details:**

1. **In-flight tracking**: Map<string, Promise<any>> to track active requests by key
2. **Deduplication logic**: If request key exists in in-flight map, return existing promise
3. **Priority queue**: Maintain sorted queue by priority (higher first)
4. **Stats tracking**: Increment counters for monitoring
5. **Concurrent limit**: Process up to 3 requests simultaneously (configurable)
6. **Error handling**: Failed requests removed from in-flight, errors logged but not thrown

**Deduplication Strategy:**
```typescript
fetch<T>(request: FetchRequest<T>): Promise<T> {
  // Check if already in-flight
  if (this.inFlightRequests.has(request.key)) {
    this.stats.deduplicated++;
    return this.inFlightRequests.get(request.key) as Promise<T>;
  }

  // Start new request
  const promise = this.executeRequest(request);
  this.inFlightRequests.set(request.key, promise);

  // Clean up when done
  promise.finally(() => this.inFlightRequests.delete(request.key));

  return promise;
}
```

**Priority Queue:**
- Use array sorted by priority (higher first)
- Process queue when slot available (< 3 concurrent)
- FIFO for equal priority

**Singleton Pattern:**
Export single instance so all widgets share same coordinator:
```typescript
export const fetchCoordinator = new FetchCoordinator();
```

Do NOT add retry logic - that's handled by existing MCP client.
Do NOT add caching - that's handled by widget-cache.ts.
Focus only on request coordination and deduplication.
  </action>
  <verify>
1. Multiple calls with same key return same promise instance
2. Stats show deduplicated count increases
3. Concurrent limit enforced (max 3 in-flight)
4. Priority queue processes higher priority first
5. Failed requests don't block queue
6. cancelAll() clears in-flight and queued requests
  </verify>
  <done>
- FetchCoordinator class created with deduplication
- In-flight request tracking with Map
- Priority queue implementation
- Stats tracking (inFlight, queued, completed, deduplicated, errors)
- Singleton instance exported
- No TypeScript errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate FetchCoordinator into ClaudeUsageCard</name>
  <files>src/components/a2ui/ClaudeUsageCard.tsx</files>
  <action>
Update ClaudeUsageCard to use fetchCoordinator instead of direct MCP client calls.

**Changes to fetchData:**

Before (current):
```typescript
const [usage, config, consoleData] = await Promise.all([
  mcpClient.getClaudeCodeUsage(undefined, 'max5'),
  mcpClient.getClaudeConfig().catch(() => null),
  mcpClient.getConsoleUsage().catch(() => null),
]);
```

After (with coordinator):
```typescript
const [usage, config, consoleData] = await Promise.all([
  fetchCoordinator.fetch({
    key: 'claude-code-usage:max5',
    fetcher: () => mcpClient.getClaudeCodeUsage(undefined, 'max5'),
    priority: 1, // Normal priority
  }),
  fetchCoordinator.fetch({
    key: 'claude-config',
    fetcher: () => mcpClient.getClaudeConfig(),
    priority: 0,
  }).catch(() => null),
  fetchCoordinator.fetch({
    key: 'console-usage',
    fetcher: () => mcpClient.getConsoleUsage(),
    priority: 2, // Higher priority for console data
  }).catch(() => null),
]);
```

**Request Keys:**
- Use descriptive, stable keys: `{service}:{operation}:{params}`
- Examples: `claude-code-usage:max5`, `console-usage`, `aws-costs:monthly`
- Ensures deduplication works across widget instances

**Priority Levels:**
- 0: Low (config, metadata)
- 1: Normal (usage stats)
- 2: High (real-time data like console usage)

Do NOT change error handling - keep existing .catch(() => null) pattern.
Do NOT change cache operations - keep setCachedWidget calls.
Only wrap MCP client calls with fetchCoordinator.fetch().
  </action>
  <verify>
1. Widget still displays cached data immediately
2. Background fetch completes successfully
3. Console shows deduplication in action (if multiple instances)
4. Cache updates after fetch
5. No regression in existing functionality
6. fetchCoordinator.getStats() shows requests processed
  </verify>
  <done>
- ClaudeUsageCard fetchData uses fetchCoordinator
- All MCP client calls wrapped with fetch()
- Request keys defined for deduplication
- Priority levels assigned
- No change to error handling or cache operations
- No TypeScript errors
  </done>
</task>

<task type="auto">
  <name>Task 3: Add cache performance monitoring</name>
  <files>src/utils/widget-cache.ts</files>
  <action>
Add monitoring to widget-cache.ts to track cache hits, misses, and performance.

**Add CacheStats interface:**
```typescript
interface CacheStats {
  hits: number;           // getCachedWidget returned data
  misses: number;         // getCachedWidget returned null
  writes: number;         // setCachedWidget calls
  deletes: number;        // deleteCachedWidget calls
  hitRate: number;        // hits / (hits + misses)
  totalSize: number;      // Approximate size in bytes
  entryCount: number;     // Number of cached entries
}
```

**Add stats tracking:**
- Increment hits when getCachedWidget returns data
- Increment misses when getCachedWidget returns null
- Increment writes when setCachedWidget called
- Increment deletes when deleteCachedWidget called
- Store stats in localStorage under 'widget-cache-stats-v1'
- Persist stats across page reloads

**Add getCacheStats() function:**
```typescript
export function getCacheStats(): CacheStats {
  const stats = loadStats();
  const cache = getCache();

  return {
    ...stats,
    hitRate: stats.hits + stats.misses > 0
      ? stats.hits / (stats.hits + stats.misses)
      : 0,
    totalSize: JSON.stringify(cache).length,
    entryCount: Object.keys(cache.entries).length,
  };
}
```

**Add resetCacheStats() function:**
Useful for testing and debugging.

**Logging:**
Add console.log for cache operations (only in verbose mode):
```typescript
// In getCachedWidget
if (result) {
  console.log(`[Cache] HIT: ${widgetType}:${cacheKey}`, ageMs);
} else {
  console.log(`[Cache] MISS: ${widgetType}:${cacheKey}`);
}
```

Use same verbose pattern as ClaudeUsageCard - always log to console for now.

Do NOT add UI for stats display - that's for later.
Do NOT change existing cache behavior - only add tracking.
Focus on accurate metrics for monitoring and optimization.
  </action>
  <verify>
1. getCacheStats() returns accurate counts
2. Hit rate calculates correctly (0-1 range)
3. Stats persist across page reloads
4. totalSize reflects actual cache size
5. entryCount matches number of cached widgets
6. Console logs show HIT/MISS for cache operations
  </verify>
  <done>
- CacheStats interface added
- Stats tracking in all cache operations
- getCacheStats() function implemented
- resetCacheStats() function added
- Stats persisted to localStorage
- Console logging for cache operations
- No TypeScript errors
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Centralized fetch coordinator with deduplication, priority queuing, and cache performance monitoring</what-built>
  <how-to-verify>
Test fetch coordination and monitoring:

1. Test deduplication:
   - Open DevTools → Console
   - Clear cache: localStorage.removeItem('widget-cache-v1')
   - Reload page multiple times quickly
   - Check Network tab: Should see only ONE request per unique data source
   - Check console logs: Should show "deduplicated" messages

2. Test cache monitoring:
   - In Console, run: `localStorage.getItem('widget-cache-stats-v1')`
   - Should see stats with hits, misses, writes counts
   - Clear cache and reload → miss count increases
   - Reload again → hit count increases
   - Calculate hit rate: hits / (hits + misses)

3. Test priority queuing:
   - Add console.log to FetchCoordinator showing request order
   - Reload page
   - Verify high-priority requests (console-usage) execute first
   - Lower priority requests (config) wait if queue full

4. Verify no regression:
   - ClaudeUsageCard still displays instantly with cache
   - Background fetch still works
   - Cache updates after fetch
   - Staleness indicator still appears
   - No console errors

5. Check fetch stats:
   - In Console, call: fetchCoordinator.getStats()
   - Should show: inFlight (should be 0 when idle), completed, deduplicated
   - Reload and call again → completed count increases
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] FetchCoordinator successfully deduplicates requests
- [ ] Priority queue processes high-priority requests first
- [ ] Cache stats track hits, misses, writes accurately
- [ ] ClaudeUsageCard works with no regressions
- [ ] Console logs show deduplication and cache operations
- [ ] No TypeScript errors or build warnings
- [ ] Fetch stats accessible via getStats()
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- FetchCoordinator handles deduplication automatically
- Multiple widget instances share fetches via coordinator
- Priority queue enforces request ordering
- Cache stats provide visibility into performance
- No regression in existing cache hydration
- No console errors or warnings
</success_criteria>

<output>
After completion, create `.planning/phases/44-background-fetch-system/44-01-SUMMARY.md`:

# Phase 44 Plan 1: Background Fetch System Summary

**[One-line description of what shipped]**

## Accomplishments

- [Key achievements]
- [Fetch coordination details]
- [Monitoring capabilities]

## Files Created/Modified

- `src/services/fetch-coordinator.ts` - Created centralized fetch coordinator
- `src/components/a2ui/ClaudeUsageCard.tsx` - Integrated fetch coordinator
- `src/utils/widget-cache.ts` - Added cache performance monitoring

## Technical Implementation

**FetchCoordinator Architecture:**
- [How deduplication works]
- [Priority queue implementation]
- [Stats tracking approach]

**Integration Pattern:**
- [How widgets use coordinator]
- [Request key strategy]
- [Priority levels]

**Monitoring:**
- [Cache stats tracked]
- [Fetch stats available]
- [Logging approach]

## Decisions Made

[Key implementation decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 44 complete (1/1 plans). Ready for Phase 45 (Smooth Update Transitions).

**Notes for Phase 45:**
- Fetch coordinator ready for use by other widgets
- Cache stats provide baseline for measuring improvements
- Priority system can be tuned based on usage patterns
</output>
